import random

array = []

for i in range(10):
    l = []

    for j in range(10):
        n = random.randint(1, 9)
        if n == 9:
            l.append(1)
        else:
            l.append(0)

    array.append(l)

array[0][0] = 0
array[9][9] = 2

for i in range(10):
  print(array[i])

# * * * * *

table = []
l = []
actions = ['up', 'down', 'left', 'right']

print(" ↑  ↓  ←  →")

for i in range(100):
    l = []

    for j in range(4):
        l.append(0)

    table.append(l)

learning_rate = 0.003
gamma = 0.9
epsilon = 0.1
curr_x = 0
curr_y = 0
available_actions = ['up', 'down', 'left', 'right']

def check_available(available_actions, x, y):
    available_actions = ['up', 'down', 'left', 'right']

    if x == 0:
        available_actions.pop(2)
    if y == 0:
        available_actions.pop(0)
    if x == 9:
        available_actions.pop(3)
    if y == 9:
        available_actions.pop(1)

    return available_actions
def epsilon_greedy(available_actions, x, y):
    available_actions = check_available(available_actions, x, y)
    #print(available_actions)

    if random.random() >= epsilon:
         return random.choice(available_actions)
    else:
        new_actions = []
        if 'left' in available_actions:
            if array[y][x - 1] == 2:
                return 'left'
            elif array[y][x - 1] != 1:
                new_actions.append('left')

        if 'right' in available_actions:
            if array[y][x + 1] == 2:
                return 'right'
            elif array[y][x + 1] != 1:
                new_actions.append('right')

        if 'up' in available_actions:
            if array[y - 1][x] == 2:
                return 'up'
            elif array[y - 1][x] != 1:
                new_actions.append('up')

        if 'down' in available_actions:
            if array[y + 1][x] == 2:
                return 'down'
            elif array[y + 1][x] != 1:
                new_actions.append('down')

        if len(new_actions) > 0:
            return random.choice(new_actions)

        return random.choice(available_actions)

curr_s = 0
next_s = 0
curr_col = 0
next_col = 0

curr_a = epsilon_greedy(available_actions, curr_x, curr_y)
next_x = 0
next_y = 0
reward = 0

if curr_a == 'left':
    next_x = curr_x - 1

    if array[next_y][next_x] == 1:
        reward = -10
    elif array[next_y][next_x] == 2:
        reward = 5

    curr_s -= 1
    curr_col = 2

elif curr_a == 'right':
    next_x = curr_x + 1

    if array[next_y][next_x] == 1:
        reward = -10
    elif array[next_y][next_x] == 2:
        reward = 5

    curr_s += 1
    curr_col = 3

elif curr_a == 'up':
    next_y = curr_y - 1

    if array[next_y][next_x] == 1:
        reward = -10
    elif array[next_y][next_x] == 2:
        reward = 5

    curr_s -= 10
    curr_col = 0

elif curr_a == 'down':
    next_y = curr_y + 1

    if array[next_y][next_x] == 1:
        reward = -10
    elif array[next_y][next_x] == 2:
        reward = 5

    curr_s += 10
    curr_col = 1

for i in range(100):
    print(table[i])

#print(curr_a)
print(curr_s, curr_col)

next_a = epsilon_greedy(available_actions, next_x, next_y)

table[curr_s][curr_col] = learning_rate * (reward + (gamma * max(table[curr_x][curr_y])) - table[curr_s][curr_col])

curr_x = next_x
curr_y = next_y
